{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy\n",
    "import numpy as np\n",
    "\n",
    "#import libraries for Naive Bayes\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import requests\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#import libraries for SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#import libraries for BI-LSTM\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing: Cleaning data using nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: @fa6ami86 so happy that salman won.  btw the 14sec clip is truely a teaser\n",
      "Cleaned: fa6ami86 happy salman btw 14sec clip truely teaser\n",
      "\n",
      "Original: @phantompoptart .......oops.... I guess I'm kinda out of it.... Blonde moment -blushes- epic fail\n",
      "Cleaned: phantompoptart oops guess kinda blonde moment blushes epic fail\n",
      "\n",
      "Original: @bradleyjp decidedly undecided. Depends on the situation. When I'm out with the people I'll be in Chicago with? Maybe.\n",
      "Cleaned: bradleyjp decidedly undecided depends situation people chicago maybe\n",
      "\n",
      "Original: @Mountgrace lol i know! its so frustrating isnt it?!\n",
      "Cleaned: mountgrace lol know frustrating isnt\n",
      "\n",
      "Original: @kathystover Didn't go much of any where - Life took over for a while\n",
      "Cleaned: kathystover go much life took\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import nltk libarary for text preprocessing\n",
    "import re\n",
    "import requests\n",
    "import nltk\n",
    "\n",
    "# Download NLTK stopwords\n",
    "import ssl\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Bypass SSL certificate verification\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "\n",
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "\n",
    "# Fetch the data\n",
    "url = \"https://datasets-server.huggingface.co/first-rows?dataset=carblacac%2Ftwitter-sentiment-analysis&config=default&split=train\"\n",
    "data = requests.get(url).json()\n",
    "texts = [row['row']['text'] for row in data['rows']]\n",
    "labels = [row['row']['feeling'] for row in data['rows']]\n",
    "\n",
    "# Function to clean and preprocess the text\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and links using regular expressions\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+|\\[.*?\\]|\\W', ' ', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the cleaning function to each text\n",
    "cleaned_texts = [clean_text(text) for text in texts]\n",
    "\n",
    "# Print cleaned text for the first few samples\n",
    "for i in range(5):\n",
    "    print(f\"Original: {texts[i]}\")\n",
    "    print(f\"Cleaned: {cleaned_texts[i]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FJ0_kgx5PGEW",
    "outputId": "53d9ee6e-3dd6-446e-e520-c4173e6b6069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.45\n",
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.62      0.48         8\n",
      "           1       0.57      0.33      0.42        12\n",
      "\n",
      "    accuracy                           0.45        20\n",
      "   macro avg       0.48      0.48      0.45        20\n",
      "weighted avg       0.50      0.45      0.44        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline with CountVectorizer and Multinomial Naive Bayes\n",
    "model_nb = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "\n",
    "# Train the model\n",
    "model_nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nb = model_nb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_nb = metrics.accuracy_score(y_test, y_pred_nb)\n",
    "print(f\"Naive Bayes Accuracy: {accuracy_nb}\")\n",
    "\n",
    "report_nb = classification_report(y_test, y_pred_nb)\n",
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(report_nb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VOZwxJoleI1G",
    "outputId": "fd273caa-5272-4aa8-b124-de056001bb67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.5\n",
      "SVM Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      1.00      0.62         8\n",
      "           1       1.00      0.17      0.29        12\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.72      0.58      0.45        20\n",
      "weighted avg       0.78      0.50      0.42        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with TfidfVectorizer and Support Vector Machine\n",
    "model_svm = make_pipeline(TfidfVectorizer(), SVC())\n",
    "\n",
    "# Train the model\n",
    "model_svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = model_svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm = metrics.accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Accuracy: {accuracy_svm}\")\n",
    "\n",
    "report_svm = classification_report(y_test, y_pred_svm)\n",
    "print(\"SVM Report:\")\n",
    "print(report_svm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BI-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2/2 [==============================] - 6s 1s/step - loss: 0.6883 - accuracy: 0.5781 - val_loss: 0.7112 - val_accuracy: 0.3750\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.6810 - accuracy: 0.5781 - val_loss: 0.7210 - val_accuracy: 0.3750\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.6708 - accuracy: 0.5781 - val_loss: 0.7264 - val_accuracy: 0.3750\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.6636 - accuracy: 0.5781 - val_loss: 0.7330 - val_accuracy: 0.3750\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.6502 - accuracy: 0.5781 - val_loss: 0.7333 - val_accuracy: 0.3750\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.6347 - accuracy: 0.5781 - val_loss: 0.7314 - val_accuracy: 0.3750\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 0.6153 - accuracy: 0.5781 - val_loss: 0.7182 - val_accuracy: 0.3750\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.5872 - accuracy: 0.7188 - val_loss: 0.7009 - val_accuracy: 0.4375\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.5515 - accuracy: 0.8438 - val_loss: 0.6771 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.5045 - accuracy: 0.8906 - val_loss: 0.6512 - val_accuracy: 0.6250\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.4567 - accuracy: 0.8750 - val_loss: 0.6347 - val_accuracy: 0.6250\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.4037 - accuracy: 0.8594 - val_loss: 0.6460 - val_accuracy: 0.6250\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 0.3472 - accuracy: 0.8906 - val_loss: 0.7096 - val_accuracy: 0.4375\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.2973 - accuracy: 0.9062 - val_loss: 0.7531 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 0.2249 - accuracy: 0.9531 - val_loss: 0.6888 - val_accuracy: 0.6875\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.1487 - accuracy: 0.9688 - val_loss: 0.7496 - val_accuracy: 0.6250\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.0700 - accuracy: 1.0000 - val_loss: 1.0389 - val_accuracy: 0.4375\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 1.2436 - val_accuracy: 0.4375\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.4066 - val_accuracy: 0.4375\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.6779 - val_accuracy: 0.4375\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.9877 - val_accuracy: 0.3750\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.1301 - val_accuracy: 0.4375\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.1372 - val_accuracy: 0.4375\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1195 - val_accuracy: 0.4375\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.3114 - val_accuracy: 0.4375\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5781 - val_accuracy: 0.4375\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.6787 - val_accuracy: 0.4375\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.5990 - val_accuracy: 0.4375\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.5705 - val_accuracy: 0.4375\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 9.2022e-04 - accuracy: 1.0000 - val_loss: 2.7939 - val_accuracy: 0.4375\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.3698 - accuracy: 0.5500\n",
      "Bi-LSTM Accuracy: 0.550000011920929\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Convert text to sequences and pad sequences\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_lstm = pad_sequences(sequences)\n",
    "\n",
    "# Convert labels to numpy array\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Convert test labels to numpy array\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train_lstm, X_val_lstm, y_train, y_val = train_test_split(X_train_lstm, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the Bi-LSTM model\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(total_words, 100, input_length=len(X_train_lstm[0])))\n",
    "model_lstm.add(Bidirectional(LSTM(64)))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_lstm.fit(np.array(X_train_lstm), y_train, epochs=30, batch_size=32, validation_data=(np.array(X_val_lstm), y_val))\n",
    "\n",
    "# Convert test data to sequences and pad sequences\n",
    "X_test_lstm = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=len(X_train_lstm[0]))\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_lstm = model_lstm.evaluate(X_test_lstm, y_test)[1]\n",
    "print(f\"Bi-LSTM Accuracy: {accuracy_lstm}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
